<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Deepfake Detection CNN - Alex Wick</title>
    <meta
      name="description"
      content="Exploration of Convolutional Neural Networks for deepfake detection, achieving 75% validation accuracy with a custom model on a challenging combined dataset."
    />
    <link rel="stylesheet" href="styles/output.css" />
  </head>
  <body
    class="font-serif bg-warm-beige dark:bg-dark-bg text-deep-navy dark:text-dark-text transition-colors duration-300"
  >
    <header
      class="fixed top-0 w-full bg-cream/90 dark:bg-dark-surface/90 backdrop-blur-md z-50 border-b border-light-grey dark:border-dark-border"
    >
      <nav class="max-w-6xl mx-auto px-6 py-4">
        <div class="flex items-center justify-between">
          <a
            href="/"
            class="font-serif font-bold text-xl text-deep-navy dark:text-dark-text"
            >Alex Wick</a
          >
          <div class="flex items-center gap-6">
            <a
              href="/#projects"
              class="text-sm font-medium text-soft-charcoal dark:text-dark-text-secondary hover:text-warm-brown dark:hover:text-dark-accent transition-colors"
              >← Back to Portfolio</a
            >
            <button
              id="theme-toggle"
              aria-label="Toggle theme"
              class="p-2 rounded-lg hover:bg-light-grey dark:hover:bg-dark-card transition-colors cursor-pointer"
            >
              <svg
                class="w-5 h-5 hidden dark:block"
                fill="currentColor"
                viewBox="0 0 20 20"
              >
                <path
                  d="M10 2a1 1 0 011 1v1a1 1 0 11-2 0V3a1 1 0 011-1zm4 8a4 4 0 11-8 0 4 4 0 018 0zm-.464 4.95l.707.707a1 1 0 001.414-1.414l-.707-.707a1 1 0 00-1.414 1.414zm2.12-10.607a1 1 0 010 1.414l-.706.707a1 1 0 11-1.414-1.414l.707-.707a1 1 0 011.414 0zM17 11a1 1 0 100-2h-1a1 1 0 100 2h1zm-7 4a1 1 0 011 1v1a1 1 0 11-2 0v-1a1 1 0 011-1zM5.05 6.464A1 1 0 106.465 5.05l-.708-.707a1 1 0 00-1.414 1.414l.707.707zm1.414 8.486l-.707.707a1 1 0 01-1.414-1.414l.707-.707a1 1 0 011.414 1.414zM4 11a1 1 0 100-2H3a1 1 0 000 2h1z"
                ></path>
              </svg>
              <svg
                class="w-5 h-5 block dark:hidden"
                fill="currentColor"
                viewBox="0 0 20 20"
              >
                <path
                  d="M17.293 13.293A8 8 0 016.707 2.707a8.001 8.001 0 1010.586 10.586z"
                ></path>
              </svg>
            </button>
          </div>
        </div>
      </nav>
    </header>

    <section class="pt-32 pb-20 px-6">
      <div class="max-w-4xl mx-auto">
        <h1 class="font-serif text-4xl md:text-6xl font-bold mb-6">
          Deepfake Detection CNN
        </h1>
        <p
          class="text-xl text-soft-charcoal dark:text-dark-text-secondary mb-8"
        >
          Exploration of Convolutional Neural Networks for deepfake detection,
          culminating in a custom CNN achieving 75% validation accuracy on a
          challenging combined dataset of real and AI-generated images.
        </p>
        <div class="flex flex-wrap gap-3 mb-8">
          <span
            class="px-4 py-2 bg-light-grey dark:bg-dark-card text-soft-charcoal dark:text-dark-text rounded-full text-sm font-medium"
            >Python</span
          >
          <span
            class="px-4 py-2 bg-light-grey dark:bg-dark-card text-soft-charcoal dark:text-dark-text rounded-full text-sm font-medium"
            >TensorFlow</span
          >
          <span
            class="px-4 py-2 bg-light-grey dark:bg-dark-card text-soft-charcoal dark:text-dark-text rounded-full text-sm font-medium"
            >Keras</span
          >
          <span
            class="px-4 py-2 bg-light-grey dark:bg-dark-card text-soft-charcoal dark:text-dark-text rounded-full text-sm font-medium"
            >CNN</span
          >
          <span
            class="px-4 py-2 bg-light-grey dark:bg-dark-card text-soft-charcoal dark:text-dark-text rounded-full text-sm font-medium"
            >VGG16</span
          >
          <span
            class="px-4 py-2 bg-light-grey dark:bg-dark-card text-soft-charcoal dark:text-dark-text rounded-full text-sm font-medium"
            >Computer Vision</span
          >
        </div>
        <div class="flex gap-4">
          <a
            href="https://devpost.com/software/lightweight-deepfake-detectors"
            target="_blank"
            rel="noopener noreferrer"
            class="bg-muted-gold dark:bg-dark-accent text-deep-navy dark:text-dark-bg px-6 py-3 rounded-lg font-semibold hover:opacity-90 transition-opacity"
          >
            View Devpost →
          </a>
        </div>
      </div>
    </section>

    <section class="py-20 px-6 bg-light-grey dark:bg-dark-surface">
      <div class="max-w-4xl mx-auto">
        <div class="mb-12">
          <h2 class="font-serif text-3xl font-bold mb-6">Overview</h2>
          <p
            class="text-lg text-soft-charcoal dark:text-dark-text-secondary mb-4"
          >
            The proliferation of highly realistic deepfakes poses a significant
            challenge to digital media integrity. This project aimed to develop
            an effective deepfake detection model. Initially, the goal was to
            improve upon the ~70% accuracy of a CNN-based model by Karandikar et
            al. (2020), which utilized the VGG16 architecture.
          </p>
          <p
            class="text-lg text-soft-charcoal dark:text-dark-text-secondary mb-4"
          >
            The project involved working with datasets like FaceForensics++
            (first-generation deepfakes) and Celeb-DF (v2) (more advanced
            deepfakes). While the VGG16-based approach showed promise (achieving
            90% validation on FaceForensics++ alone and 75.69% on a combined
            dataset), it faced challenges with overfitting and complexity when
            applied to the harder, combined dataset.
          </p>
          <p class="text-lg text-soft-charcoal">
            This led to the development of a lighter, custom Convolutional
            Neural Network (CNN) from scratch. This custom CNN, with
            approximately 6.5 million parameters, ultimately achieved an 75%
            validation accuracy on the challenging combined dataset,
            outperforming the VGG16-based approach on the same data. The project
            began after an initial exploration of DefakeHop++, which was pivoted
            away from due to its limited use of deep learning techniques.
          </p>
        </div>

        <div class="mb-12">
          <h2 class="font-serif text-3xl font-bold mb-6">
            Technical Approach & Model Architectures
          </h2>
          <p
            class="text-lg text-soft-charcoal dark:text-dark-text-secondary mb-4"
          >
            The project explored two main CNN-based approaches for deepfake
            detection after an initial pivot:
          </p>
          <ul
            class="list-disc list-inside text-lg text-soft-charcoal dark:text-dark-text-secondary space-y-6 ml-4"
          >
            <li>
              <strong>VGG16-based Model with Custom Head:</strong>
              <ul
                class="list-disc list-inside text-base text-soft-charcoal dark:text-dark-text-secondary space-y-1 ml-6 mt-2"
              >
                <li>
                  Utilized transfer learning, leveraging the pretrained
                  convolutional layers of VGG16.
                </li>
                <li>
                  A custom classification head was added, differing from the
                  original Karandikar et al. paper by using a binary
                  classification output with a sigmoid activation and a revised
                  layer ordering to potentially reduce overfitting.
                </li>
                <li>
                  Data preprocessing involved face detection (libface detector),
                  cropping with a 30% margin, and alignment (cv2). Frames were
                  selected to ensure balanced classes.
                </li>
                <li>
                  This model had ~14.7M parameters from VGG16 and ~1.7M from the
                  custom head.
                </li>
              </ul>
            </li>
            <li>
              <strong>Custom CNN Model (from scratch):</strong>
              <ul
                class="list-disc list-inside text-base text-soft-charcoal dark:text-dark-text-secondary space-y-1 ml-6 mt-2"
              >
                <li>
                  Developed to address the complexity and overfitting issues
                  encountered with the VGG16-based model.
                </li>
                <li>Totaled approximately 6.5 million parameters.</li>
                <li>
                  Architecture included:
                  <ul
                    class="list-disc list-inside text-sm text-soft-charcoal dark:text-dark-text-secondary space-y-1 ml-6 mt-1 font-mono"
                  >
                    <li>
                      Conv2D (32 filters, 3x3) -> BatchNormalization ->
                      MaxPool2D
                    </li>
                    <li>
                      Conv2D (64 filters, 3x3) -> BatchNormalization ->
                      MaxPool2D
                    </li>
                    <li>
                      Conv2D (64 filters, 3x3) -> BatchNormalization ->
                      MaxPool2D
                    </li>
                    <li>Flatten</li>
                    <li>
                      Dense (64, LeakyReLU, L2 regularizer) -> Dropout(0.5) ->
                      BatchNormalization
                    </li>
                    <li>
                      Dense (64, LeakyReLU, L2 regularizer) -> Dropout(0.5) ->
                      BatchNormalization
                    </li>
                    <li>Dense (1, sigmoid, L2 regularizer)</li>
                  </ul>
                </li>
                <li>
                  This model achieved the highest validation accuracy (75%) on
                  the combined dataset.
                </li>
              </ul>
            </li>
          </ul>
        </div>

        <div class="mb-12">
          <h2 class="font-serif text-3xl font-bold mb-6">Key Results</h2>
          <div class="grid grid-cols-1 md:grid-cols-3 gap-6">
            <div class="bg-cream dark:bg-dark-card p-6 rounded-lg text-center">
              <h3
                class="text-3xl font-bold text-muted-gold dark:text-dark-accent mb-2"
              >
                75%
              </h3>
              <p class="text-soft-charcoal dark:text-dark-text-secondary">
                Validation Accuracy (Custom CNN on Combined FF++ & Celeb-DF v2)
              </p>
            </div>
            <div class="bg-cream dark:bg-dark-card p-6 rounded-lg text-center">
              <h3
                class="text-3xl font-bold text-muted-gold dark:text-dark-accent mb-2"
              >
                75.7%
              </h3>
              <p class="text-soft-charcoal dark:text-dark-text-secondary">
                Validation Accuracy (VGG16-based on Combined FF++ & Celeb-DF v2)
              </p>
            </div>
            <div class="bg-cream dark:bg-dark-card p-6 rounded-lg text-center">
              <h3
                class="text-3xl font-bold text-muted-gold dark:text-dark-accent mb-2"
              >
                90%
              </h3>
              <p class="text-soft-charcoal dark:text-dark-text-secondary">
                Validation Accuracy (VGG16-based on FaceForensics++ only)
              </p>
            </div>
          </div>
          <p
            class="text-sm text-soft-charcoal dark:text-dark-text-secondary mt-4"
          >
            The original Karandikar et al. (2020) paper reported ~70% accuracy
            with their VGG16-based model. Both models developed in this project
            surpassed that on comparable tasks.
          </p>
        </div>

        <div class="mb-12">
          <h2 class="font-serif text-3xl font-bold mb-6">
            Challenges & Learnings
          </h2>
          <p
            class="text-lg text-soft-charcoal dark:text-dark-text-secondary mb-4"
          >
            Several challenges were encountered and overcome during development:
          </p>
          <ul
            class="list-disc list-inside text-lg text-soft-charcoal dark:text-dark-text-secondary space-y-2 ml-4"
          >
            <li>
              <strong>Overfitting:</strong> This was the primary challenge,
              especially with the complex VGG16 model on the combined dataset,
              leading to a persistent gap between training and validation
              accuracies. Various techniques like regularization, dropout, and
              hyperparameter tuning were explored.
            </li>
            <li>
              <strong>Data Augmentation:</strong> Attempts to use data
              augmentation (e.g., noise, brightness adjustment) yielded mixed
              results, sometimes worsening overfitting. Transformative
              augmentations (rotation, zoom) interfered with the facial
              alignment preprocessing.
            </li>
            <li>
              <strong>Preprocessing Imperfections:</strong> The face detection
              algorithm occasionally misidentified non-face objects (e.g.,
              buttons, posters) as faces, potentially impacting model training.
              Manually checking nearly 100,000 frames was infeasible.
            </li>
            <li>
              <strong>Hardware Constraints:</strong> Training was performed on
              an M2 MacBook Pro. Limited computational resources and disk space
              made it challenging to effectively parallelize
              preprocessing/training and handle the large datasets required for
              optimal fine-tuning of VGG16.
            </li>
            <li>
              <strong>Initial Project Pivot:</strong> The project initially
              aimed to implement DefakeHop++, but pivoted to a CNN-based
              approach after discovering DefakeHop++ lacked substantial deep
              learning components.
            </li>
          </ul>
        </div>

        <div class="mb-12">
          <h2 class="font-serif text-3xl font-bold mb-6">
            Future Enhancements
          </h2>
          <p
            class="text-lg text-soft-charcoal dark:text-dark-text-secondary mb-4"
          >
            Potential improvements and future directions for the model include:
          </p>
          <ul
            class="list-disc list-inside text-lg text-soft-charcoal dark:text-dark-text-secondary space-y-2 ml-4"
          >
            <li>
              Implementing a more fine-tuned transfer learning approach for
              VGG16, involving unfreezing more layers and training with a very
              low learning rate, potentially with a larger dataset if hardware
              permits.
            </li>
            <li>
              Further developing and refining the lightweight custom CNN
              architecture, which showed promising results in balancing
              performance and complexity.
            </li>
          </ul>
        </div>
      </div>
    </section>

    <section class="py-20 px-6 dark:bg-dark-bg">
      <div class="max-w-4xl mx-auto text-center">
        <h2 class="font-serif text-2xl font-bold mb-8">Next Project</h2>
        <a
          href="project-weenix.html"
          class="inline-flex items-center gap-2 text-warm-brown dark:text-dark-accent font-medium hover:underline"
        >
          Weenix Operating System
          <svg
            class="w-4 h-4"
            fill="none"
            stroke="currentColor"
            viewBox="0 0 24 24"
          >
            <path
              stroke-linecap="round"
              stroke-linejoin="round"
              stroke-width="2"
              d="M9 5l7 7-7 7"
            ></path>
          </svg>
        </a>
      </div>
    </section>

    <footer
      class="py-8 px-6 border-t border-light-grey dark:border-dark-border dark:bg-dark-bg"
    >
      <div
        class="max-w-6xl mx-auto text-center text-sm text-soft-charcoal dark:text-dark-text-secondary"
      >
        <p>© 2025 Alex Wick. All rights reserved.</p>
      </div>
    </footer>

    <script src="main.js"></script>
  </body>
</html>
